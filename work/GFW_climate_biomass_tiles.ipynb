{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generate Context tiles\n",
    "\n",
    "This notebook shows how to generate context tiles for products like GFW and GFW Climate, via example:\n",
    "\n",
    "### GFW Climate Biomass \n",
    "\n",
    "[GFW climate](http://climate.globalforestwatch.org/map/3/-28.56/79.56/ALL/dark/biomass_loss?begin=2001-11-10&end=2015-01-01&threshold=30) shows Carbon emissions from biomass loss (t CO2/ha).\n",
    "\n",
    "![](./pics/gfw_biomass.png)\n",
    "\n",
    "These data enable the user to select a tree cover canopy threshold of interest, and show biomass loss over time, enabling the user to select the time range of interest. \n",
    "\n",
    "The data come from webmap tiles.\n",
    "\n",
    "For example, an old versions of these data produced by Google in 2014 are hosted at:\n",
    "\n",
    "http://storage.googleapis.com/earthenginepartners-wri/whrc-hansen-carbon-{threshold}-{z}{/x}{/y}.png\n",
    "\n",
    "These tiles are decoded by clientside javascript code [here](https://github.com/Vizzuality/gfw-climate/blob/develop/app/assets/javascripts/map/views/layers/BiomassLossLayer.js), and converted into a visulization of biomass loss.\n",
    "\n",
    "If we zoom into some disctinct areas and examine the contents of the tile we will be able to understand more how these data are put together, and how to replicate them.\n",
    "\n",
    "We will look at two informative areas, one in Jamaica, which shows 3 clear patches of carbon loss imposed over a small iland area, easy to identify:\n",
    "\n",
    "<img src=\"./pics/Jamaica.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "And another which shows the data cutoff and a distinct error in the previously processed data over the Floridian peninsula:\n",
    "\n",
    "<img src=\"./pics/florida.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import maya\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def deg2num(lat_deg, lon_deg, zoom):\n",
    "    \"\"\"Based on a zoom and lat long, get tile numbers\"\"\"\n",
    "    lat_rad = math.radians(lat_deg)\n",
    "    n = 2.0 ** zoom\n",
    "    xtile = int((lon_deg + 180.0) / 360.0 * n)\n",
    "    ytile = int((1.0 - math.log(math.tan(lat_rad) + (1 / math.cos(lat_rad))) / math.pi) / 2.0 * n)\n",
    "    return (xtile, ytile)\n",
    "\n",
    "deg2num(17.73, -77.18, 9) # position of Jamaica \n",
    "\n",
    "deg2num(30.12, -83.25, 7) # position north of Florida anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tile_url = 'http://storage.googleapis.com/earthenginepartners-wri/whrc-hansen-carbon-30-9/146/230.png'\n",
    "#tile_url = 'http://storage.googleapis.com/earthenginepartners-wri/whrc-hansen-carbon-30-7/34/52.png'\n",
    "im_arrays = misc.imread(requests.get(tile_url, stream=True).raw, mode='RGBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for n, band in enumerate([\"R\",\"G\",\"B\",\"A\"]):\n",
    "    print(f\"BAND {n}  {band}: max={im_arrays[:,:,n].max()} min={im_arrays[:,:,n].min()}\")\n",
    "    plt.imshow(im_arrays[:,:,n], cmap='Oranges')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Red channel (band 0): encodes integer year - 2000 (i.e. years since 2000) of tree cover loss for trees >= a specified canopy threshold. With 0 values indicating points where no loss occured.\n",
    "\n",
    "* Green channel (band 1): Biomass masked by year (and also uncertainty to constrain to tropics), scaled with unitScale(0, 450) and converted to 255\n",
    "\n",
    "* Blue channel (band 2): Biomass (t/ha) scaled with unitScale(0, 450) and converted to 255. This should be unpacked on the front-end using ((value/917)*255)\n",
    "\n",
    "* Alpha Channel (band 3): Uncertainty (t/ha) scaled to 255 using the formulae from the E.E. dataset 'users/davethau/whrc_carbon_test/uncertainty' with clamp(0,100) scaled to 255.\n",
    "\n",
    "\n",
    "Note, in relation to the front-end code, the alpha channel of the decoded png data is not being used. I.e. the alpha channel of the above dataset is not currently being used by the front-end for anything.\n",
    "\n",
    "Note: By checking the Florida anomaly its possible to verify that everwhere has been masked by the uncertainty data.\n",
    "\n",
    "\n",
    "### A look at a histogram of the alpha channel\n",
    "\n",
    "Looks like the clamp() function has been used on the uncertainty data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(im_arrays[:,:,3].flatten(), bins=50)\n",
    "plt.ylim(0,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate the dataset\n",
    "\n",
    "Using updated WHRC biomass data and updated Hansen tree cover data, we now need to re-create the Tau dataset.\n",
    "\n",
    "1. First, we need to recreate the dataset images in the four bands.\n",
    "2. Then we need to set the resolution of the layers, iterating through z-levels, downscaling with MODE\n",
    "3. At each tree-cover threshold and z-level we need to write out the datasets as a tiles.\n",
    "\n",
    "### Testing\n",
    "\n",
    "The first stage will be visually testing these data as I create them using Folium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import json\n",
    "import folium\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inline_map(map):\n",
    "    \"\"\"\n",
    "    Embeds the HTML source of the map directly into the IPython notebook.\n",
    "    \n",
    "    This method will not work if the map depends on any files (json data). Also this uses\n",
    "    the HTML5 srcdoc attribute, which may not be supported in all browsers.\n",
    "    \"\"\"\n",
    "    map._build_map()\n",
    "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
    "\n",
    "\n",
    "def embed_map(map, path=\"map.html\"):\n",
    "    \"\"\"\n",
    "    Embeds a linked iframe to the map into the IPython notebook.\n",
    "    \n",
    "    Note: this method will not capture the source of the map into the notebook.\n",
    "    This method should work for all maps (as long as they use relative urls).\n",
    "    \"\"\"\n",
    "    map.create_map(path=path)\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path=path))\n",
    "\n",
    "\n",
    "def tile_url(image, viz_params=None):\n",
    "    \"\"\"Create a target url for tiles for an image.\n",
    "    e.g.\n",
    "    im = ee.Image(\"LE7_TOA_1YEAR/\" + year).select(\"B3\",\"B2\",\"B1\")\n",
    "    viz = {'opacity': 1, 'gain':3.5, 'bias':4, 'gamma':1.5}\n",
    "    url = tile_url(image=im),viz_params=viz)\n",
    "    \"\"\"\n",
    "    if viz_params:\n",
    "        d = image.getMapId(viz_params)\n",
    "    else:\n",
    "        d = image.getMapId()\n",
    "    base_url = 'https://earthengine.googleapis.com'\n",
    "    url = (base_url + '/map/' + d['mapid'] + '/{z}/{x}/{y}?token=' + d['token'])\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biomass uncertainty data (which also serves as a PanTropical mask)\n",
    "uncertainty = ee.Image('users/davethau/whrc_carbon_test/uncertainty')\n",
    "\n",
    "def get_biomass(uncertainty=uncertainty):\n",
    "    \"\"\" Create Woods Hole RC Biomass data image, scaled by x/917 * 255\n",
    "        and converted to byte type.\n",
    "    \"\"\"\n",
    "    neotropic = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Neotropic')\n",
    "    africa = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Africa')\n",
    "    australia = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Australia')\n",
    "    tropasia = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Tropical_Asia')\n",
    "    palearctic = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Palearctic')\n",
    "    nearctic = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Nearctic')\n",
    "    # Combine the individual areas into a single collection\n",
    "    ic = ee.ImageCollection([africa,australia, nearctic,\n",
    "                                 neotropic, palearctic, tropasia])\n",
    "    im = ic.max() # Now we have single image, but with discontinuties\n",
    "    hansenImage = ee.Image('UMD/hansen/global_forest_change_2015')\n",
    "    datamask = hansenImage.select('datamask')\n",
    "    mask = datamask.eq(1)\n",
    "    land = mask # Make a land image out of the mask\n",
    "    landmask = im.mask(land) # Mask land with itself to mask all the zeros (non-land)\n",
    "    # make another collection from the landmask and the full coverage image\n",
    "    ic_with_mask = ee.ImageCollection([landmask, im])\n",
    "    # Finally convert that into a fully contingous image, with 0s where no data over land\n",
    "    # and mask those data by uncertainty (as the original data were).\n",
    "    biomass = ic_with_mask.max()\n",
    "    biomass = biomass.mask(uncertainty).divide(917).multiply(255).byte()\n",
    "    return biomass\n",
    "\n",
    "\n",
    "def get_loss_year(threshold, uncertainty=uncertainty):\n",
    "    \"\"\"lossyear = get_loss_year(30) # get loss by year for canopy threshold of >30%\n",
    "    This function expects that the uncertainty image has already been added to the namespace.\n",
    "    \"\"\"\n",
    "    treeThresh = 30         # <--- Tree Thresholding set here (make this a function call in the future)\n",
    "    raw_hansen = ee.Image(\"UMD/hansen/global_forest_change_2016_v1_4\") # Up-to-date Hansen data\n",
    "    tree_threshold_mask = raw_hansen.select('treecover2000').gte(threshold) \n",
    "    lossyear_for_threshold = raw_hansen.select('lossyear').mask(tree_threshold_mask)\n",
    "    loss_by_year = lossyear_for_threshold.mask(lossyear_for_threshold).mask(uncertainty)\n",
    "    loss_by_year = loss_by_year.mask(loss_by_year)    \n",
    "    return loss_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomass = get_biomass()\n",
    "loss_by_year = get_loss_year(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = ee.Feature(ee.Geometry.Polygon(\n",
    "        [[[-122.6953125, 31.95216223802497],\n",
    "          [-71.015625, 30.44867367928756],\n",
    "          [-52.734375, 14.944784875088372],\n",
    "          [-39.375, 4.214943141390651],\n",
    "          [-15.8203125, 3.5134210456400448],\n",
    "          [-30.5859375, 16.299051014581828],\n",
    "          [-25.3125, 26.431228064506442],\n",
    "          [-15.1171875, 34.30714385628804],\n",
    "          [36.5625, 32.84267363195431],\n",
    "          [54.4921875, 20.3034175184893],\n",
    "          [67.8515625, 33.72433966174761],\n",
    "          [127.265625, 30.44867367928756],\n",
    "          [136.0546875, 28.304380682962783],\n",
    "          [125.5078125, 19.973348786110602],\n",
    "          [131.484375, 11.867350911459306],\n",
    "          [142.3828125, 11.178401873711785],\n",
    "          [140.9765625, 7.013667927566642],\n",
    "          [175.78125, -11.5230875068685],\n",
    "          [169.1015625, -18.979025953255267],\n",
    "          [136.40625, -12.897489183755892],\n",
    "          [107.578125, -11.867350911459296],\n",
    "          [90.3515625, 0.3515602939922709],\n",
    "          [78.3984375, 1.054627942275887],\n",
    "          [73.828125, -4.915832801313165],\n",
    "          [60.46875, 4.565473550710278],\n",
    "          [49.5703125, -1.4061088354351594],\n",
    "          [55.546875, -15.284185114076422],\n",
    "          [50.9765625, -28.92163128242129],\n",
    "          [39.0234375, -28.613459424004418],\n",
    "          [34.1015625, -33.13755119234614],\n",
    "          [11.25, -33.13755119234614],\n",
    "          [5.9765625, -18.979025953255267],\n",
    "          [6.328125, -7.01366792756663],\n",
    "          [-5.625, -1.7575368113083125],\n",
    "          [-30.234375, -3.5134210456400323],\n",
    "          [-36.2109375, -21.94304553343817],\n",
    "          [-45.3515625, -32.842673631954305],\n",
    "          [-74.53125, -33.13755119234614],\n",
    "          [-86.8359375, -6.315298538330034],\n",
    "          [-97.03125, -5.615985819155327]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some visulisation styles\n",
    "\n",
    "pinkViz = {'min': 0, 'max': 16, 'palette': 'FDC1E3, D581B1, BD257C',}\n",
    "\n",
    "whrcPALETTE = \"75322B,84512A,8E6232,da8c19,ef9e0b,ffc011,ffdb2d,\\\n",
    "          ffe215,f9eb46,d5e400,c9d800,becc00,b4c200,B7B95B,B2B659,AFB457,ABB156,\\\n",
    "          A6AE53,A3AB52,A1AA51,9FA950,9EA850,9CA74F,9BA64E,9AA54E,99A44D,95A24C,\\\n",
    "          92A04A,909E49,8C9C48,8B9A47,869745,859745,839544,839543,819443,7E9241,\\\n",
    "          7A8F40,778D3E,758C3E,758B3D,728A3C,71893C,70883B,6F873B,6D863A,6A8438,\\\n",
    "          678237,648036,627E37,607D34,5E7B33,5A7831,577630,53742E,50722D,4F712C,\\\n",
    "          4E702C,4C6F2B,4A6D2A,496D29,486C29,486C29,476B29,466A28,426827,3E6525,\\\n",
    "          3B6323,3A6223,396222,386122,355F21,345E22,315C1F,305B1E,2C591D,2B581C,\\\n",
    "          28561B,27551A,255419,245319,235218,225218,225118,215118,205017,1F4F17,\\\n",
    "          1C4E16,1B4D15,1A4C15,194C14,184A14,164913,154812,124711,114610,114610,\\\n",
    "          114610,114610\"\n",
    "          \n",
    "whrcViz = {\"max\":255,\"min\":0, 'palette': whrcPALETTE}\n",
    "\n",
    "greenViz = {'palette':'ffffff, 009933, 336600, 233f00'}\n",
    "\n",
    "polygonViz = {'opacity': 0.3, 'color': 'a97ad6'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which tileset you want to preview (folium can only show one at a time currently)\n",
    "\n",
    "#ee_tiles = tile_url(x,pinkViz)\n",
    "#ee_tiles = tile_url(loss_by_year, pinkViz)\n",
    "ee_tiles = tile_url(band2, whrcViz)\n",
    "#ee_tiles = tile_url(tree_threshold_mask, greenViz)\n",
    "#ee_tiles = tile_url(ee.Feature(geom), polygonViz)\n",
    "\n",
    "\n",
    "map = folium.Map(location=[-2.53, -46.54], zoom_start=7, tiles='Mapbox Bright' )\n",
    "map.add_tile_layer(tiles=ee_tiles, max_zoom=14, min_zoom=0, attr='Earth Engine tiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "## Script the generation of downscaled tiles\n",
    "\n",
    "Now that we have the three datasets we need loaded, masked and subset required to generate the tiled data, we now need to rigidly set the downsampling method, so as to ensure that the data have the correct apperance at each z-level. We cannot use the default pyramiding scheme. Instead, we will need to iterate over the z-levels, and at each step reduce (using mode) and reproject the data to a new fixed pixel size. We then export the data for that z-level only within the `geom` polygon .\n",
    "\n",
    "An example of this methodology in action can be seen [here](https://github.com/wri/hansen_ee_processing/blob/master/python/hansen_tiles.py).\n",
    "\n",
    "Metadta of z-relation to pixel size at equator described [here](https://developers.google.com/earth-engine/exporting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertainty():\n",
    "    uncertainty = ee.Image('users/davethau/whrc_carbon_test/uncertainty').clamp(0, 100).multiply(2.55)\n",
    "    return uncertainty\n",
    "\n",
    "\n",
    "def get_biomass(uncertainty):\n",
    "    \"\"\" Create Woods Hole RC Biomass data image, scaled by x/917 * 255\n",
    "        and converted to byte type.\n",
    "    \"\"\"\n",
    "    neotropic = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Neotropic')\n",
    "    africa = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Africa')\n",
    "    australia = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Australia')\n",
    "    tropasia = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Tropical_Asia')\n",
    "    palearctic = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Palearctic')\n",
    "    nearctic = ee.Image('users/mfarina/Biomass_Data_MapV3/WHRC_Biomass_30m_Nearctic')\n",
    "    # Combine the individual areas into a single collection\n",
    "    ic = ee.ImageCollection([africa,australia, nearctic,\n",
    "                                 neotropic, palearctic, tropasia])\n",
    "    im = ic.max() # Now we have single image, but with discontinuties\n",
    "    hansenImage = ee.Image('UMD/hansen/global_forest_change_2015')\n",
    "    datamask = hansenImage.select('datamask')\n",
    "    mask = datamask.eq(1)\n",
    "    land = mask # Make a land image out of the mask\n",
    "    landmask = im.mask(land) # Mask land with itself to mask all the zeros (non-land)\n",
    "    # make another collection from the landmask and the full coverage image\n",
    "    ic_with_mask = ee.ImageCollection([landmask, im])\n",
    "    # Finally convert that into a fully contingous image, with 0s where no data over land\n",
    "    # and mask those data by uncertainty (as the original data were).\n",
    "    biomass = ic_with_mask.max()\n",
    "    biomass = biomass.mask(uncertainty).divide(917).multiply(255).byte()\n",
    "    return biomass\n",
    "\n",
    "\n",
    "def get_loss_year(threshold, uncertainty):\n",
    "    \"\"\"lossyear = get_loss_year(30) # get loss by year for canopy threshold of >30%\n",
    "    This function expects that the uncertainty image has already been added to the namespace.\n",
    "    \"\"\"\n",
    "    treeThresh = 30         # <--- Tree Thresholding set here (make this a function call in the future)\n",
    "    raw_hansen = ee.Image(\"UMD/hansen/global_forest_change_2016_v1_4\") # Up-to-date Hansen data\n",
    "    tree_threshold_mask = raw_hansen.select('treecover2000').gte(threshold) \n",
    "    lossyear_for_threshold = raw_hansen.select('lossyear').mask(tree_threshold_mask)\n",
    "    loss_by_year = lossyear_for_threshold.mask(lossyear_for_threshold).mask(uncertainty)\n",
    "    loss_by_year = loss_by_year.mask(loss_by_year)    \n",
    "    return loss_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geom():\n",
    "    return ee.Geometry.Polygon(\n",
    "            [[[-122.6953125, 31.95216223802497],\n",
    "              [-71.015625, 30.44867367928756],\n",
    "              [-52.734375, 14.944784875088372],\n",
    "              [-39.375, 4.214943141390651],\n",
    "              [-15.8203125, 3.5134210456400448],\n",
    "              [-30.5859375, 16.299051014581828],\n",
    "              [-25.3125, 26.431228064506442],\n",
    "              [-15.1171875, 34.30714385628804],\n",
    "              [36.5625, 32.84267363195431],\n",
    "              [54.4921875, 20.3034175184893],\n",
    "              [67.8515625, 33.72433966174761],\n",
    "              [127.265625, 30.44867367928756],\n",
    "              [136.0546875, 28.304380682962783],\n",
    "              [125.5078125, 19.973348786110602],\n",
    "              [131.484375, 11.867350911459306],\n",
    "              [142.3828125, 11.178401873711785],\n",
    "              [140.9765625, 7.013667927566642],\n",
    "              [175.78125, -11.5230875068685],\n",
    "              [169.1015625, -18.979025953255267],\n",
    "              [136.40625, -12.897489183755892],\n",
    "              [107.578125, -11.867350911459296],\n",
    "              [90.3515625, 0.3515602939922709],\n",
    "              [78.3984375, 1.054627942275887],\n",
    "              [73.828125, -4.915832801313165],\n",
    "              [60.46875, 4.565473550710278],\n",
    "              [49.5703125, -1.4061088354351594],\n",
    "              [55.546875, -15.284185114076422],\n",
    "              [50.9765625, -28.92163128242129],\n",
    "              [39.0234375, -28.613459424004418],\n",
    "              [34.1015625, -33.13755119234614],\n",
    "              [11.25, -33.13755119234614],\n",
    "              [5.9765625, -18.979025953255267],\n",
    "              [6.328125, -7.01366792756663],\n",
    "              [-5.625, -1.7575368113083125],\n",
    "              [-30.234375, -3.5134210456400323],\n",
    "              [-36.2109375, -21.94304553343817],\n",
    "              [-45.3515625, -32.842673631954305],\n",
    "              [-74.53125, -33.13755119234614],\n",
    "              [-86.8359375, -6.315298538330034],\n",
    "              [-97.03125, -5.615985819155327]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale(img_at_z_plus_1, z, z_max=12):\n",
    "    if z == z_max:\n",
    "        return img_at_z_plus_1\n",
    "    else:\n",
    "        return img_at_z_plus_1.reproject(\n",
    "                    scale=z_to_m[z+1],\n",
    "                    crs=\"EPSG:4326\"\n",
    "                ).reduceResolution(\n",
    "                    reducer=ee.Reducer.mode(),\n",
    "                    maxPixels=max_pixs\n",
    "                ).reproject(\n",
    "                        scale=z_to_m[z],\n",
    "                        crs=\"EPSG:4326\"\n",
    "                )\n",
    "\n",
    "\n",
    "def get_write_target(bucket, version, threshold):\n",
    "    \"\"\" e.g. get_write_target('gfw-climate-tiles', 2.0, 30)\"\"\"\n",
    "    return '{}/biomassloss/v{}/tc{}'.format(bucket, str(version), str(threshold))\n",
    "\n",
    "\n",
    "def export_tiles(image, z, v, threshold, geom, verbose=False):\n",
    "    \"\"\"Create tiles for a specified z level.\n",
    "    z = z-level (integer between 0 and 23)\n",
    "    v = version number of a dataset (e.g. 1.0)\n",
    "    threshold = integer tree cover threshold\n",
    "    geom = ee.geometry object within setting the region from\n",
    "            within which to generate tiles\n",
    "    verbose = True to print status\n",
    "    \"\"\"\n",
    "    tiles_path = get_write_target('gfw-climate-tiles', v, threshold)\n",
    "    name=tiles_path.replace('/','_')\n",
    "    if verbose: print('tiles:', z, tiles_path, name)\n",
    "    task=ee.batch.Export.map.toCloudStorage(\n",
    "        fileFormat='png',\n",
    "        image=image,\n",
    "        description='{}_{}'.format(name, z), \n",
    "        bucket='gfw-climate-tiles', \n",
    "        path=tiles_path, \n",
    "        writePublicTiles=True, \n",
    "        maxZoom=z, \n",
    "        minZoom=z, \n",
    "        region=geom.coordinates().getInfo(), \n",
    "        skipEmptyTiles=True\n",
    "    )\n",
    "    task.start()\n",
    "    if verbose: print(task.status())\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=27.829872698318393\n",
    "max_pixs=65500\n",
    "full_intensity=255\n",
    "thresholds=[10, 15, 20, 25, 30, 50, 75]\n",
    "\n",
    "# dictionary of z to meteres\n",
    "z_to_m = {0: 156000,\n",
    "          1: 78000,\n",
    "          2: 39000,\n",
    "          3: 20000,\n",
    "          4: 10000,\n",
    "          5: 4900,\n",
    "          6: 2400,\n",
    "          7: 1200,\n",
    "          8: 611,\n",
    "          9: 305,\n",
    "          10: 152,\n",
    "          11: 76,\n",
    "          12: 38}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing z12: 38m\n",
      "processing z11: 76m\n",
      "processing z10: 152m\n",
      "processing z9: 305m\n",
      "processing z8: 611m\n",
      "processing z7: 1,200m\n",
      "Writing z7\n",
      "tiles: 7 gfw-climate-tiles/biomassloss/v2.0/tc10 gfw-climate-tiles_biomassloss_v2.0_tc10\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "Must be owner of bucket gfw-climate-tiles to write public tiles.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ddb9cd55e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Writing z{z}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             export_tiles(image=final_image, z=z, v=2.0, threshold=threshold,\n\u001b[0;32m---> 23\u001b[0;31m                          geom=geom, verbose=True)\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shouldnt see this - we only want to do one threshold to begin with'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d0bbad6ce853>\u001b[0m in \u001b[0;36mexport_tiles\u001b[0;34m(image, z, v, threshold, geom, verbose)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mskipEmptyTiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ee/batch.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m       raise ee_exception.EEException(\n\u001b[1;32m     72\u001b[0m           'Task config must be specified for tasks to be started.')\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36mstartProcessing\u001b[0;34m(taskId, params)\u001b[0m\n\u001b[1;32m    522\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaskId\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msend_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/processingrequest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36msend_\u001b[0;34m(path, params, opt_method, opt_raw)\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid JSON: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Malformed response: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEEException\u001b[0m: Must be owner of bucket gfw-climate-tiles to write public tiles."
     ]
    }
   ],
   "source": [
    "geom = get_geom()\n",
    "for threshold in thresholds:\n",
    "    # At the start of each threshold category, get the data and mask by threshold, loss and uncertainty\n",
    "    band4 = get_uncertainty()\n",
    "    band1 = get_loss_year(threshold, uncertainty=band4) # loss yr masked by uncertainty and TC threshold\n",
    "    band3 = get_biomass(uncertainty=band4)  # Biomass masked by uncertainty\n",
    "    band2 = band3.mask(band1) # Biomass masked by loss-yr, TC threshold and uncertainty\n",
    "    # For each z-level starting from 12 ending at 3\n",
    "    for z in range(12, 2, -1):\n",
    "        print(f'processing z{z}: {z_to_m[z]:,g}m' )\n",
    "        # Downscale the bands according to the z level\n",
    "        band1 = downscale(band1, z)\n",
    "        band2 = downscale(band2, z)\n",
    "        band3 = downscale(band3, z)\n",
    "        band4 = downscale(band4, z)\n",
    "        # Add the bands to a single image\n",
    "        final_image = band1.addBands(band2).addBands(\n",
    "            band3).addBands(band4).rename('year', 'total_biomass_loss', 'density','alpha')\n",
    "        # write to tiles specifically for the threshold and z-level of the current loop\n",
    "        if z == 7:\n",
    "            print(f'Writing z{z}')\n",
    "            export_tiles(image=final_image, z=z, v=2.0, threshold=threshold,\n",
    "                         geom=geom, verbose=True)\n",
    "    break\n",
    "    print('shouldnt see this - we only want to do one threshold to begin with')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
