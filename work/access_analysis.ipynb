{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of access data\n",
    "\n",
    "> **Developing some interactive visualisations that highlight key statistics from our access data.** This consists of a series of spreadsheets, providing details of applications to SYNTHESYS for researcher visits to participating Natural History Collections across Europe, and the research outputs (primarily publications) generated through these visits. Depending on the consistency of these datasets we will try to provide them through to the first iteration of SYSTHESYS so they will cover about 4k funded research projects. Various aspects of these data (including unsuccessful applications) might be explored and we will work with you to highlight these, alongside a handful of high profile projects which we may seek to promote.\n",
    "\n",
    "## Table of contents\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1. Read and understand the access data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/Ben/Work/Vizzuality/SYNTHESIS/Data/FullExportAnon_v3.csv\", encoding=\"mac_cyrillic\")  # this dataset is private!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names in dataframe\n",
    "sorted(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "These data contain repeated entries, in that a user can make a single application that has in it requests to use more than one resource, and in this case, they will end up with multiple rows (one for each resource request). Therefore data can be over-represnted in the df. Need to identify these cases, and re-make the dataset accordingly.\n",
    "\n",
    "To parse applications that have multiple rows of data but should be only one entry, I should look for cases where the fields `Application_ID`, `UserProject_ID` and `HostInstName1` match, and then condense down the `NHM_Installation_Use.Installation_Long_Name` entries for all matches into one entry row only. Then I should perform the statistical analysis on this new table to ensure I am not multiple-counting the same application in the analysis.\n",
    "\n",
    "There's one column where you might need to condense the values differently though - `NHM_Installation_use.Amount_of_Access_delivered` separates out the total number of access days delivered by installation, so the new/condensed entry row should contain the sum of values in the original rows. `ProjectsView.length_of_visit`, on the other hand, has the same value duplicated throughout, which can just be used in the new row without any operations required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_multiple_entries(df):\n",
    "    \"\"\"Provided a subset of a dataframe (which is intended only to be a subset where multiple entries \n",
    "    for the same applicant and project exist), we will condense down the data to a single row\n",
    "    in order not to overweight such projects in the summary statistics.\n",
    "    This will return a list tmp_row (list) which should be appended to a base_list. The keys will\n",
    "    also be outputted (as they are not simply the same as the input dataframe).\n",
    "    \"\"\"\n",
    "    tmp_row=[]    # hold each specific row, temporarily\n",
    "    key_list =[]  # hold only a list of the keys we are going to pass, in the specific order of access\n",
    "    for key in sorted(df.keys()):\n",
    "        unique_element_entries = df[key].unique()\n",
    "        if len(unique_element_entries) == 1:\n",
    "            tmp_row.append(unique_element_entries[0])\n",
    "            key_list.append(key)\n",
    "        else:\n",
    "            if key in ['NHM_Installation_Use.Installation_Long_Name',\n",
    "                       'NHM_Installation_Use.Installation_Short_Name']:\n",
    "                unique_element_entries = \" &&& \".join(unique_element_entries) # encode info into a single string\n",
    "                key_list.append(key)\n",
    "                tmp_row.append(unique_element_entries)\n",
    "                #print(f\"key = {key}, entry = {unique_element_entries}\")\n",
    "            if key in ['NHM_Installation_Use.Amount_of_Access_Delivered']:\n",
    "                unique_element_entries = unique_element_entries.sum()\n",
    "                key_list.append(key)\n",
    "                tmp_row.append(unique_element_entries)\n",
    "                #print(f\"key = {key}, entry = {unique_element_entries}\")\n",
    "            if key in ['NHM_Installation_Use.Installation_ID',\n",
    "                       'HostInstName1',\n",
    "                       'NHM_Installation_Use.Infrastructure_Short_Name']:\n",
    "                string_ids = list(unique_element_entries)\n",
    "                x_ids = [ str(ids) for ids in string_ids]\n",
    "                x_ids = ' &&& '.join(x_ids)\n",
    "                key_list.append(key)\n",
    "                tmp_row.append(x_ids)\n",
    "                #print(f\"key = {key}, entry = {x_ids}\")\n",
    "    return tmp_row, key_list\n",
    "    #new_base.append(tmp_row)  # After compressing each set of rows into a single row, add it to the new frame\n",
    "\n",
    "\n",
    "#pd.DataFrame(new_base, columns=key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parsing dataset to remove multiple entries per user id and application id\")\n",
    "print(\"Adding ' &&& ' between all grouped strings\")\n",
    "print(\"Summing visit days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look for cases where Application_ID UserProject_ID and HostInstName1 match\n",
    "unique_applications = sorted(set(df['Application_ID'].values))\n",
    "\n",
    "new_data = []\n",
    "\n",
    "# For unique projects and applicants only have one row of data\n",
    "for application in tqdm(unique_applications[0:]):  # <<----limit here\n",
    "    applicant_mask = df['Application_ID']==application\n",
    "    number_of_applications = len(df[applicant_mask])\n",
    "    #print(f\" Applicant: {application}\")#, Num entries:{number_of_applications}\")\n",
    "    if number_of_applications > 1:\n",
    "        applicant_df = df[applicant_mask]\n",
    "        project_ids = applicant_df['UserProject_ID'].unique()\n",
    "        #print(f\"     {number_of_applications} applications over {len(project_ids)} projects \")\n",
    "        for project_id in project_ids:\n",
    "            #print(f\"{application} {project_id}\")\n",
    "            mask_project_id = applicant_df['UserProject_ID'] == project_id\n",
    "            df_same_applicant_and_project = applicant_df[mask_project_id]\n",
    "            v, k = group_multiple_entries(df_same_applicant_and_project)\n",
    "            #print(f\"A: number of value entries: {len(v)}, number of key entries:{len(k)}\")\n",
    "            new_data.append(v)\n",
    "        if len(k) < 31:\n",
    "            print(\"Found bug!\")\n",
    "            break\n",
    "    else:\n",
    "        v, k = group_multiple_entries(df[applicant_mask])\n",
    "        #print(f\"B: number of value entries: {len(v)}, number of key entries:{len(k)}\")\n",
    "        new_data.append(v)\n",
    "print(\"parsed dataset\")\n",
    "xdf = pd.DataFrame(new_data, columns=k)\n",
    "print(\"created new dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Parsing reduced original dataframe by {len(df) - len(xdf):,g} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw = df # Save the old DF\n",
    "df = xdf    # Overwrite the df keyword with the new (one row per project version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring individual reccuring users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Access dataset has {len(df):,g} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = len(df['User_Code'].unique())\n",
    "print(f\"User_Code, the Anonymised user id column has {unique_users:,g} unqique entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_users = Counter(df['User_Code']).most_common() # count and order the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_users[0:10]  # The top 10 users by number of appearances in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reccurence = [user_reccurence[1] for user_reccurence in d_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a simple histogram with binsize determined automatically\n",
    "sns.distplot(reccurence, kde=False, color=\"b\", axlabel='Number of visits')\n",
    "plt.title(\"Reccuring users\")\n",
    "plt.ylabel(\"Number of user codes\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is actually diffrent when user_codes are the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask = df['User_Code'] == 'User1124'\n",
    "df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the most frequently appearing users data:\n",
    "\n",
    "def give_date(year, month, day):\n",
    "    months = {'January': 1, 'Feburary': 2, 'March':3, 'April':4, 'May':5,\n",
    "              'June':6, \"July\":7, \"August\":8,\"September\":9, \"October\":10,\n",
    "              \"November\":11, \"December\":12}\n",
    "    return pd.datetime(int(year), months['November'], int(day))\n",
    "\n",
    "\n",
    "\n",
    "for index, row in df[mask].iterrows():\n",
    "    date = give_date(row['ProjectStart_Year'], row['ProjectStart_Month'], row['ProjectStart_Day'])\n",
    "    age = row['Applicant_Age_Visit_Start']\n",
    "    to_use = row['NHM_Installation_Use.Installation_Long_Name']\n",
    "    calls = row['Call_Submitted']\n",
    "    print('Start:',date.date(), \"age:\",age, calls, to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the unique codes in the data and their meaning?\n",
    "\n",
    "In many places the data have shorthand codes, we will need to relate this shorthand to their actual meaning.\n",
    "\n",
    "I can also use the Counter object here to get a first-pass idea of the frequency of each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['Call_Submitted']).most_common() # Not sure what this is exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['User_NHM.Home_Institution_Type']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different classifications of institute types. \n",
    "* UNI = University\n",
    "* RES = Research Organisation\n",
    "* OTH = Other\n",
    "* SME = Small-to-medium Enterprise\n",
    "* PRV = Private Organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['User_NHM.Researcher_status']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different levels\n",
    "* EXP = Experienced Researcher\n",
    "* PDOC = Postdoctoral\n",
    "* PGR = Postgraduate\n",
    "* UND = Undergraduate\n",
    "* TEC = Technician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['Call_Submitted']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls need to be combined with year. In each phase of SYNTHESYS there were a certain number of 'Calls' for applications for Access.\n",
    "* S1 (2004-2008) - we had 9 calls\n",
    "* S2 (2008-2012) - 4 calls\n",
    "* S3 (2013-2017) - 4 calls\n",
    "\n",
    "So the frequency of calls 1-4 will be much higher than 5-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['NHM_Installation_Use.Amount_of_Access_Delivered']).most_common()[0:5] # Basically, amount of visit days funded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['NHM_Disciplines.DisciplineName']).most_common()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at disciplines via the `NHM_Disciplines.DisciplineName` variable, we have 2 catagories dominating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['NHM_Specific_Disciplines.SpecificDisciplineName']).most_common()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead we look at disciplines via `NHM_Specific_Disciplines.SpecificDisciplineName` we get 5 substantial (>200 row) categories. This is a good number for displaying a break-down. We can aggregate those with < 200 rows int an other category.\n",
    "\n",
    "Below we can examine the installations people are using. I have looked at these broken down by category, and it seems not to bear a strong correlation to discipline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['NHM_Installation_Use.Installation_Long_Name']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess this means the number of times a unique researcher has applied for funding with the same combination of variables (will need to confirm this). If true, this might mean that if their researcher status changes, or affiliation, they would be given a different ID?\n",
    "\n",
    "\n",
    "'Applicant_Age_Visit_Start'\n",
    "\n",
    "'User_NHM.Gender'\n",
    "      \n",
    "'User_NHM.Researcher_status'\n",
    "      \n",
    "'HostInstName1',\n",
    "     \n",
    "'User_NHM.Home_Institution_Name'\n",
    "\n",
    "'User_NHM.Home_Institution_Type'\n",
    "     \n",
    "'User_NHM.Home_Institution_Town'\n",
    "     \n",
    "'User_NHM.Home_Institution_Country_code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-stats\n",
    "\n",
    "A generic statistical summary of the entire dataset in text form.\n",
    "* X number of people\n",
    "* X number of institutes\n",
    "* X number of countries\n",
    "* X number of access days granted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days = df['ProjectsView.length_of_visit'].sum()\n",
    "print(f\"{total_days:,g} research days at NHM installations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = len(df['User_Code'].unique())\n",
    "print(f\"{unique_users:,g} unique users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_institutes = len(df['User_NHM.Home_Institution_Name'].unique())\n",
    "print(f\"Visitors from {unique_institutes:,g} different institutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = len(df['User_NHM.Home_Institution_Country_code'].unique())\n",
    "print(f\"Visitors from {unique_countries:,g} countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown: Statistical analysis of specific columns of the dataset\n",
    "\n",
    "#### Age of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distribution(df, key, xlabel=None, ylabel=None, title=None):\n",
    "    # Return a distribution plot e.g. to show the Age of users in a df object\n",
    "    sns.distplot(df[key].values, kde=True, color=\"b\", axlabel=xlabel)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age of users for all collection\n",
    "distribution(df, key='Applicant_Age_Visit_Start', ylabel=\"User age at start of project\", xlabel='Age',\n",
    "             title=\"Age of users (non-unique)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def donut_plot(df, column_key, fix_keys=None, colors=None, json=False):\n",
    "    \"\"\"Pass an arbritrary dataframe with a key, and optional color scheme.\n",
    "    Return a donut plot.\n",
    "    \"\"\"\n",
    "    gender_counts = Counter(df[column_key])\n",
    "    labels = []\n",
    "    values = []\n",
    "    if not fix_keys:\n",
    "        for key in gender_counts:\n",
    "            labels.append(key)\n",
    "            values.append(gender_counts[key])\n",
    "    else:\n",
    "        for key in fix_keys:\n",
    "            labels.append(key)\n",
    "            values.append(gender_counts[key])        \n",
    "    if json:\n",
    "        return dict(gender_counts)\n",
    "    else:\n",
    "        explode = 0\n",
    "        explode = (explode,) * len(labels)\n",
    "        plt.pie(values, explode=explode, labels=labels,colors=colors,\n",
    "                autopct='%1.1f%%', shadow=False)\n",
    "        centre_circle = plt.Circle((0,0),0.75,color='black', fc='white',linewidth=0.75)\n",
    "        fig = plt.gcf()\n",
    "        fig.gca().add_artist(centre_circle)\n",
    "        plt.axis('equal')\n",
    "        plt.title(\"Gender balance\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender balance of all users\n",
    "donut_plot(df, column_key='User_NHM.Gender', fix_keys=[\"M\",\"F\"], colors=['lightskyblue', 'pink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can directly get the json instead like this \n",
    "donut_plot(df, column_key='User_NHM.Gender', json=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NHM Institution Destination of the users\n",
    "\n",
    "Going to need to change this - it should take into account the number of days a person spends at each faccility (not just the number of times the faccility appears in the dataset).\n",
    "\n",
    "This data will need to come from the original dataframe (where faccilities and days are not aggregated), in order to access the number of days visited at each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visits_destination(df, otherize_threshold=None, json=False):\n",
    "    \"\"\"Pass in a dataframe and return a plot of visitors Installation destination\"\"\"\n",
    "    place_list = Counter(df['NHM_Installation_Use.Installation_Long_Name']).most_common()\n",
    "    if otherize_threshold:\n",
    "        top_list_with_other=[]\n",
    "        other_sum = 0\n",
    "        percent_limit = int(len(df)*otherize_threshold)\n",
    "        cumulative = 0\n",
    "        for k,v in place_list:\n",
    "            cumulative += v\n",
    "            if cumulative < percent_limit:\n",
    "                top_list_with_other.append([k,v])\n",
    "            else:\n",
    "                other_sum += v\n",
    "        top_list_with_other.append(['other', other_sum])\n",
    "        place_list = top_list_with_other\n",
    "    if json:\n",
    "        return dict(place_list)\n",
    "    else:\n",
    "        places = []\n",
    "        visits = []\n",
    "        for c, num in place_list:\n",
    "            places.append(c)\n",
    "            visits.append(num)\n",
    "        place_visists = pd.DataFrame(place_list, columns=['Installation','visits'])\n",
    "        f, ax = plt.subplots(figsize=(6, 10))\n",
    "        # Plot the total crashes\n",
    "        sns.set_color_codes(\"pastel\")\n",
    "        sns.barplot(x=\"visits\", y=\"Installation\", data=place_visists,\n",
    "                    label=\"Total\", color=\"r\")\n",
    "        ax.set(ylabel='Installation', xlabel=\"number of visits\", title=\"Visits by Installation\")\n",
    "        sns.despine(left=True, bottom=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_destination(df, otherize_threshold=0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple reporting of Counts and mean age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_stats(df):\n",
    "    \"\"\"For a dataframe print some stats we care about\"\"\"\n",
    "    count = df['Applicant_Age_Visit_Start'].describe()['count']\n",
    "    mean_age = df['Applicant_Age_Visit_Start'].describe()['mean']\n",
    "    stdev_age = df['Applicant_Age_Visit_Start'].describe()['std']\n",
    "    print(f\"{count:g} visits. Average age = {mean_age:3.1f}±{stdev_age:3.1f}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_stats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification of users Specific Discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visitor_discipline(df, otherize_threshold=None, json=False):\n",
    "    \"\"\"Pass in a dataframe and return a plot of visitors per country.\n",
    "    If you want the cumulative 95% to apper, and the last 5% to be grouped into other,\n",
    "    then for example, set otherize_threshol=0.95\n",
    "    \"\"\"\n",
    "    # 'NHM_Specific_Disciplines.SpecificDisciplineName'\n",
    "    # 'NHM_Disciplines.DisciplineName'\n",
    "    tmp = Counter(df['NHM_Specific_Disciplines.SpecificDisciplineName']).most_common()\n",
    "    \n",
    "    if otherize_threshold:\n",
    "        top_list_with_other=[]\n",
    "        other_sum = 0\n",
    "        percent_limit = int(len(df)*otherize_threshold)\n",
    "        cumulative = 0\n",
    "        for k,v in tmp:\n",
    "            cumulative += v\n",
    "            if cumulative < percent_limit:\n",
    "                top_list_with_other.append([k,v])\n",
    "            else:\n",
    "                other_sum += v\n",
    "        top_list_with_other.append(['other', other_sum])\n",
    "        tmp = top_list_with_other\n",
    "    if json:\n",
    "        return dict(tmp)\n",
    "    else:\n",
    "        topics = []\n",
    "        visits = []\n",
    "        for c,num in tmp:\n",
    "            topics.append(c)\n",
    "            visits.append(num)\n",
    "        discipline_visists = pd.DataFrame(tmp, columns=['disciplines','visits'])\n",
    "        f, ax = plt.subplots(figsize=(6, 10))\n",
    "        sns.set_color_codes(\"pastel\")\n",
    "        sns.barplot(x=\"visits\", y=\"disciplines\", data=discipline_visists,\n",
    "                    label=\"Total\", color=\"g\")\n",
    "        ax.set(ylabel='Country', xlabel=\"number of visits\", title=\"Visits by discipline\")\n",
    "        sns.despine(left=True, bottom=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitor_discipline(df, otherize_threshold=0.985, json=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breakdown of users by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visits_per_country(df, otherize_threshold=None):\n",
    "    \"\"\"Pass in a dataframe and return a plot of visitors per country\"\"\"\n",
    "    countries = Counter(df['User_NHM.Home_Institution_Country_code']).most_common()\n",
    "    if otherize_threshold:\n",
    "        top_list_with_other=[]\n",
    "        other_sum = 0\n",
    "        percent_limit = int(len(df)*otherize_threshold)\n",
    "        cumulative = 0\n",
    "        for k,v in countries:\n",
    "            cumulative += v\n",
    "            if cumulative < percent_limit:\n",
    "                top_list_with_other.append([k,v])\n",
    "            else:\n",
    "                other_sum += v\n",
    "        top_list_with_other.append(['other', other_sum])\n",
    "        countries = top_list_with_other\n",
    "    places = []\n",
    "    visits = []\n",
    "    for c,num in countries:\n",
    "        places.append(c)\n",
    "        visits.append(num)\n",
    "    country_visists = pd.DataFrame(countries, columns=['country','visits'])\n",
    "    f, ax = plt.subplots(figsize=(6, 10))\n",
    "    sns.set_color_codes(\"pastel\")\n",
    "    sns.barplot(x=\"visits\", y=\"country\", data=country_visists,\n",
    "                label=\"Total\", color=\"b\")\n",
    "    ax.set(ylabel='Country', xlabel=\"number of visits\", title=\"Visits by country\")\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_per_country(df, otherize_threshold=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Lenght of users visit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case I will need to order by the keys, not the values\n",
    "# Also, I want a displot again here.\n",
    "Counter(df['ProjectsView.length_of_visit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution(df, key='ProjectsView.length_of_visit',\n",
    "             xlabel='length of visit (days)', ylabel='density',\n",
    "             title=\"Lenght of visit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'NHM_Specific_Disciplines.SpecificDisciplineName'\n",
    "# 'NHM_Disciplines.DisciplineName'\n",
    "filter_var = 'NHM_Specific_Disciplines.SpecificDisciplineName'\n",
    "for discipline,_ in Counter(df[filter_var]).most_common():\n",
    "    if isinstance(discipline, str):\n",
    "        print(f\"\\nDISCIPLINE: {discipline.capitalize()}\")\n",
    "        mask = df[filter_var] == discipline\n",
    "        if len(df[mask]) > 100:\n",
    "            group_stats(df[mask])\n",
    "            distribution(df[mask], key='Applicant_Age_Visit_Start',\n",
    "                         ylabel=\"User age at start of project\", xlabel='Age',\n",
    "                         title=f\"Age of users (non-unique) for {discipline}\")\n",
    "            donut_plot(df[mask], column_key='User_NHM.Gender', \n",
    "                       fix_keys=[\"M\",\"F\"], colors=['lightskyblue', 'pink'])\n",
    "            visits_per_country(df[mask], otherize_threshold=0.90)\n",
    "            visits_destination(df[mask], otherize_threshold=0.98)\n",
    "            distribution(df[mask], key='ProjectsView.length_of_visit',\n",
    "                         xlabel='length of visit (days)', ylabel='density',\n",
    "                         title=\"Lenght of visit\")   \n",
    "        else:\n",
    "            print(f\"Only {len(df[mask])} entries for discipline. Not sufficent for analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Filtering by Researcher Origin Country\n",
    "\n",
    "Examples of what it looks like to do summary stats per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for country, _ in Counter(df['User_NHM.Home_Institution_Country_code']).most_common():\n",
    "    print(f\"Data grouped for {country}:\")\n",
    "    mask = df['User_NHM.Home_Institution_Country_code'] == country\n",
    "    if len(df[mask]) > 100:\n",
    "        group_stats(df[mask])\n",
    "        donut_plot(df[mask], column_key='User_NHM.Gender', \n",
    "                   fix_keys=[\"M\",\"F\"], colors=['lightskyblue', 'pink'])\n",
    "        distribution(df[mask], key='Applicant_Age_Visit_Start',\n",
    "                     ylabel=\"User age at start of project\", xlabel='Age',\n",
    "                     title=f\"Age of users (non-unique) from {country}\")\n",
    "        visitor_discipline(df[mask], otherize_threshold=0.98)\n",
    "        visits_destination(df[mask], otherize_threshold=0.98)\n",
    "        distribution(df[mask], key='ProjectsView.length_of_visit',\n",
    "                     xlabel='length of visit (days)', ylabel='density',\n",
    "                     title=\"Lenght of visit\")   \n",
    "    else:\n",
    "        print(f\"Only {len(df[mask])} entries for {country}; Not sufficent for meaningful analysis.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Need to get the the country codes of NHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a table to hold these processed data and simplify the data request\n",
    "\n",
    "I can put these statistical views into a country-wise and discipline-wise statistical summary view of the access data. Seems that filtering by country or by discipline will create small dictionaries that we can load directly into webpages to make things fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={}\n",
    "for country, _ in Counter(df['User_NHM.Home_Institution_Country_code']).most_common():\n",
    "    country_d = {}\n",
    "    if country == country:\n",
    "        mask = df['User_NHM.Home_Institution_Country_code'] == country\n",
    "        country_d['sex'] = donut_plot(df[mask], column_key='User_NHM.Gender', json=True)\n",
    "        country_d['destination'] = visits_destination(df[mask], json=True)\n",
    "        country_d['discipline']=visitor_discipline(df[mask], json=True)\n",
    "        d[country] = country_d\n",
    "\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#json = json.dumps(d)\n",
    "#with open(\"./test_per_country.json\",\"w\") as f:\n",
    "#    f.write(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Publication data\n",
    "\n",
    "we can associate publications to institutions and years rather than people that would help (if that's doable).  In terms of de-anonymisation I think the main concern is that we want to avoid people being able to connect a record to someone's personal info and application history.  Interactive demographic summary stats I think should be OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers_data = pd.from_xls(\"/Users/Ben/Work/VIzzuality/SYNTHESIS/Data/synthpubs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
